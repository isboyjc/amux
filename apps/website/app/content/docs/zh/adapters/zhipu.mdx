---
title: Zhipu 适配器
description: 使用 Zhipu 适配器连接智谱 AI 的 GLM 系列模型
---

Zhipu 适配器提供了与智谱 AI（Zhipu AI）API 的集成。智谱 AI 提供了 GLM 系列大语言模型，API 完全兼容 OpenAI 格式。

## 安装

```bash tab="pnpm"
pnpm add @amux.ai/llm-bridge @amux.ai/adapter-zhipu
```

```bash tab="npm"
npm install @amux.ai/llm-bridge @amux.ai/adapter-zhipu
```

## 基本使用

```typescript
import { createBridge } from '@amux.ai/llm-bridge'
import { zhipuAdapter } from '@amux.ai/adapter-zhipu'

const bridge = createBridge({
  inbound: zhipuAdapter,
  outbound: zhipuAdapter,
  config: {
    apiKey: process.env.ZHIPU_API_KEY,
  },
})

const response = await bridge.chat({
  model: 'glm-4.7',
  messages: [
    { role: 'system', content: '你是一个智能助手。' },
    { role: 'user', content: '什么是 Amux？' },
  ],
})

console.log(response.choices[0].message.content)
```

## 支持的模型

智谱 AI 提供多种 GLM 模型：

| 模型    | 描述                       |
| ------- | -------------------------- |
| glm-4.7 | 最新一代旗舰模型，性能最强 |
| glm-4.6 | 高性能模型，平衡性能与成本 |
| glm-4.5 | 高性价比模型，适合日常任务 |
| glm-4v  | 支持视觉理解的多模态模型   |

<Callout type="info">
  智谱 AI 的模型持续更新，请参考官方文档获取最新的模型列表。
</Callout>

## 主要功能

<Tabs items={['基础对话', '函数调用', '流式传输']}>
  <Tab value="基础对话">
    ### 基础对话

    ```typescript
    const response = await bridge.chat({
      model: 'glm-4.7',
      messages: [
        { role: 'user', content: '介绍一下智谱AI' }
      ],
      temperature: 0.7,
      max_tokens: 1000
    })
    ```

  </Tab>

  <Tab value="函数调用">
    ### 函数调用

    ```typescript
    const response = await bridge.chat({
      model: 'glm-4.7',
      messages: [
        { role: 'user', content: '北京现在几点？' }
      ],
      tools: [{
        type: 'function',
        function: {
          name: 'get_current_time',
          description: '获取指定城市的当前时间',
          parameters: {
            type: 'object',
            properties: {
              city: { type: 'string', description: '城市名称' }
            },
            required: ['city']
          }
        }
      }]
    })
    ```

  </Tab>

  <Tab value="流式传输">
    ### 流式传输

    ```typescript
    const stream = bridge.chatStreamRaw({
      model: 'glm-4.7',
      messages: [
        { role: 'user', content: '讲一个故事' }
      ],
      stream: true
    })

    for await (const event of stream) {
      if (event.type === 'content') {
        process.stdout.write(event.content.delta)
      }
    }
    ```

  </Tab>
</Tabs>

## 配置选项

```typescript
const bridge = createBridge({
  inbound: zhipuAdapter,
  outbound: zhipuAdapter,
  config: {
    apiKey: process.env.ZHIPU_API_KEY,
    baseURL: 'https://open.bigmodel.cn/api/paas', // 默认值
    timeout: 60000,
  },
})
```

## 功能支持

| 功能      | 支持 | 说明                                           |
| --------- | ---- | ---------------------------------------------- |
| 聊天补全  | ✅   | 完全支持                                       |
| 流式传输  | ✅   | 完全支持                                       |
| 函数调用  | ✅   | 完全支持                                       |
| 视觉      | ⚠️   | 已声明能力；当前出站适配器路径主要拼接文本分片 |
| 系统提示  | ✅   | 完全支持                                       |
| JSON 模式 | ✅   | 完全支持                                       |
| 网络搜索  | ⚠️   | 已声明能力；当前适配器暂无专用请求字段映射     |

<Callout type="warn">
  当前适配器边界说明：

- 构建 Zhipu 出站请求时会过滤 `tool_choice = 'required'`。
- 出站消息构建器目前会将多模态分片压平为文本。
  </Callout>

## 最佳实践

### 1. 根据需求选择模型

```typescript
// 日常任务使用性价比模型
const quickResponse = await bridge.chat({
  model: 'glm-4.5',
  messages: [{ role: 'user', content: '你好' }],
})

// 复杂任务使用旗舰模型
const complexTask = await bridge.chat({
  model: 'glm-4.7',
  messages: [{ role: 'user', content: '请分析这段代码的性能问题...' }],
})
```

### 2. 使用系统提示优化输出

```typescript
const response = await bridge.chat({
  model: 'glm-4.7',
  messages: [
    {
      role: 'system',
      content: '你是一个专业的技术文档撰写助手。请用简洁、专业的语言回答问题。',
    },
    {
      role: 'user',
      content: '什么是 RESTful API？',
    },
  ],
})
```

### 3. 处理多轮对话

```typescript
const messages = [
  { role: 'user', content: '第一个问题' },
  { role: 'assistant', content: '第一个回答' },
  { role: 'user', content: '继续追问' },
]

const response = await bridge.chat({
  model: 'glm-4.7',
  messages,
})
```

## 与 OpenAI 互转

智谱 AI 完全兼容 OpenAI 格式：

```typescript
import { openaiAdapter } from '@amux.ai/adapter-openai'
import { zhipuAdapter } from '@amux.ai/adapter-zhipu'

const bridge = createBridge({
  inbound: openaiAdapter,
  outbound: zhipuAdapter,
  config: {
    apiKey: process.env.ZHIPU_API_KEY,
  },
})

// 使用 OpenAI 格式发送请求
const response = await bridge.chat({
  model: 'gpt-4',
  messages: [{ role: 'user', content: '你好' }],
})
```

## 相关资源

- [智谱 AI 官网](https://www.zhipuai.cn/)
- [智谱 AI API 文档](https://open.bigmodel.cn/dev/api)
- [智谱 AI 定价](https://open.bigmodel.cn/pricing)

## 下一步

<Cards>
  <Card title="DeepSeek 适配器" href="/zh/docs/adapters/deepseek">
    了解如何使用 DeepSeek 模型
  </Card>
  <Card title="Moonshot 适配器" href="/zh/docs/adapters/moonshot">
    了解如何使用 Moonshot 模型
  </Card>
</Cards>

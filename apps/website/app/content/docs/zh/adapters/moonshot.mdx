---
title: Moonshot 适配器
description: 使用 Moonshot 适配器连接月之暗面的 Kimi 系列模型
---

Moonshot 适配器提供了与月之暗面（Moonshot AI）API 的集成。Moonshot 以超长上下文（200K tokens）著称，API 完全兼容 OpenAI 格式。

## 安装

```bash tab="pnpm"
pnpm add @amux.ai/llm-bridge @amux.ai/adapter-moonshot
```

```bash tab="npm"
npm install @amux.ai/llm-bridge @amux.ai/adapter-moonshot
```

## 基本使用

```typescript
import { createBridge } from '@amux.ai/llm-bridge'
import { moonshotAdapter } from '@amux.ai/adapter-moonshot'

const bridge = createBridge({
  inbound: moonshotAdapter,
  outbound: moonshotAdapter,
  config: {
    apiKey: process.env.MOONSHOT_API_KEY,
  },
})

const response = await bridge.chat({
  model: 'moonshot-v1-8k',
  messages: [
    {
      role: 'system',
      content: '你是 Kimi，由月之暗面科技提供的人工智能助手。',
    },
    { role: 'user', content: '什么是 Amux？' },
  ],
})

console.log(response.choices[0].message.content)
```

## 支持的模型

| 模型                   | 上下文长度 | 描述             |
| ---------------------- | ---------- | ---------------- |
| `moonshot-v1-8k`       | 8K         | 标准上下文模型   |
| `kimi-k2-0905-preview` | -          | Kimi K2 预览版   |
| `kimi-k2-thinking`     | -          | Kimi K2 思考模型 |

<Callout type="info">
  Moonshot 的最大特点是支持超长上下文，适合处理长文档、长对话等场景。
</Callout>

## 主要功能

<Tabs items={['长上下文', '函数调用', '流式传输']}>
  <Tab value="长上下文">
    ### 超长上下文

    Moonshot 支持超长上下文：

    ```typescript
    const response = await bridge.chat({
      model: 'moonshot-v1-8k',
      messages: [
        {
          role: 'user',
          content: `请总结以下长文档：\n\n${longDocument}`
        }
      ]
    })
    ```

    **使用场景：**
    - 长文档分析和总结
    - 多轮长对话
    - 代码库分析
    - 学术论文阅读

  </Tab>

  <Tab value="函数调用">
    ### 函数调用

    ```typescript
    const response = await bridge.chat({
      model: 'moonshot-v1-8k',
      messages: [
        { role: 'user', content: '北京现在几点？' }
      ],
      tools: [{
        type: 'function',
        function: {
          name: 'get_current_time',
          description: '获取指定城市的当前时间',
          parameters: {
            type: 'object',
            properties: {
              city: { type: 'string', description: '城市名称' }
            },
            required: ['city']
          }
        }
      }]
    })
    ```

  </Tab>

  <Tab value="流式传输">
    ### 流式传输

    ```typescript
    const stream = bridge.chatStreamRaw({
      model: 'moonshot-v1-8k',
      messages: [
        { role: 'user', content: '讲一个故事' }
      ],
      stream: true
    })

    for await (const event of stream) {
      if (event.type === 'content') {
        process.stdout.write(event.content.delta)
      }
    }
    ```

  </Tab>
</Tabs>

## 配置选项

```typescript
const bridge = createBridge({
  inbound: moonshotAdapter,
  outbound: moonshotAdapter,
  config: {
    apiKey: process.env.MOONSHOT_API_KEY,
    baseURL: 'https://api.moonshot.cn', // 默认值
    timeout: 60000,
  },
})
```

## 功能支持

| 功能      | 支持 | 说明           |
| --------- | ---- | -------------- |
| 聊天补全  | ✅   | 完全支持       |
| 流式传输  | ✅   | 完全支持       |
| 函数调用  | ✅   | 完全支持       |
| 长上下文  | ✅   | 支持超长上下文 |
| 视觉      | ❌   | 不支持         |
| 系统提示  | ✅   | 完全支持       |
| JSON 模式 | ✅   | 结构化输出     |

<Callout type="warn">
  当前 Moonshot 出站请求构建器不会透传 `tool_choice = 'required'`。
</Callout>

## 最佳实践

### 1. 根据需求选择模型

```typescript
// 短对话使用 8K 模型（更快更便宜）
const shortChat = await bridge.chat({
  model: 'moonshot-v1-8k',
  messages: [{ role: 'user', content: '你好' }],
})

// 复杂推理使用 thinking 模型
const complexTask = await bridge.chat({
  model: 'kimi-k2-thinking',
  messages: [{ role: 'user', content: '请分析这个复杂问题...' }],
})
```

### 2. 优化长文档处理

```typescript
const response = await bridge.chat({
  model: 'moonshot-v1-8k',
  messages: [
    {
      role: 'system',
      content: '你是一个专业的文档分析助手。提供简洁、结构化的总结。',
    },
    {
      role: 'user',
      content: `请总结以下文档的要点：\n\n${document}`,
    },
  ],
  temperature: 0.3, // 降低温度以获得更准确的总结
})
```

### 3. 处理多轮对话

```typescript
// Moonshot 支持长对话历史
const messages = [
  { role: 'user', content: '第一个问题' },
  { role: 'assistant', content: '第一个回答' },
  // ... 可以有很多轮
  { role: 'user', content: '最新的问题' },
]

const response = await bridge.chat({
  model: 'moonshot-v1-8k',
  messages,
})
```

## 与 OpenAI 互转

Moonshot 完全兼容 OpenAI 格式：

```typescript
import { openaiAdapter } from '@amux.ai/adapter-openai'
import { moonshotAdapter } from '@amux.ai/adapter-moonshot'

const bridge = createBridge({
  inbound: openaiAdapter,
  outbound: moonshotAdapter,
  config: {
    apiKey: process.env.MOONSHOT_API_KEY,
  },
})

// 使用 OpenAI 格式发送请求
const response = await bridge.chat({
  model: 'gpt-4',
  messages: [{ role: 'user', content: '你好' }],
})
```

## 相关资源

- [Moonshot API 文档](https://platform.moonshot.cn/docs)
- [Moonshot 定价](https://platform.moonshot.cn/pricing)

## 下一步

<Cards>
  <Card title="Qwen 适配器" href="/zh/docs/adapters/qwen">
    了解如何使用通义千问模型
  </Card>
  <Card title="DeepSeek 适配器" href="/zh/docs/adapters/deepseek">
    了解如何使用 DeepSeek 模型
  </Card>
</Cards>

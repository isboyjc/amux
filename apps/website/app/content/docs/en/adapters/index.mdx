---
title: Adapters Overview
description: All official adapters supported by Amux
---

Amux provides 8 official adapters supporting mainstream LLM providers. Each adapter handles bidirectional conversion between provider-specific formats and a unified intermediate representation (IR).

## Official Adapters

<Cards>
  <Card title="OpenAI" href="/en/docs/adapters/openai">
    GPT-4, GPT-3.5, function calling, vision
  </Card>
  <Card title="Anthropic" href="/en/docs/adapters/anthropic">
    Claude 3.5 Sonnet, Claude 3 Opus, 200K context
  </Card>
  <Card title="DeepSeek" href="/en/docs/adapters/deepseek">
    DeepSeek Chat, DeepSeek Coder, high value
  </Card>
  <Card title="Moonshot" href="/en/docs/adapters/moonshot">
    Kimi models, 200K ultra-long context
  </Card>
  <Card title="Zhipu" href="/en/docs/adapters/zhipu">
    GLM-4 series, web search support
  </Card>
  <Card title="Qwen" href="/en/docs/adapters/qwen">
    Qwen series, vision and multimodal
  </Card>
  <Card title="Google Gemini" href="/en/docs/adapters/gemini">
    Gemini Pro, 1M+ tokens context
  </Card>
  <Card title="MiniMax" href="/en/docs/adapters/minimax">
    MiniMax-M2.1, Interleaved Thinking, multilingual programming
  </Card>
</Cards>

## Feature Comparison

| Adapter   | Streaming | Tools | Vision | Multimodal | Reasoning | JSON Mode |
| --------- | --------- | ----- | ------ | ---------- | --------- | --------- |
| OpenAI    | ✅        | ✅    | ✅     | ✅         | ❌        | ✅        |
| Anthropic | ✅        | ✅    | ✅     | ✅         | ✅        | ❌        |
| DeepSeek  | ✅        | ✅    | ❌     | ❌         | ✅        | ✅        |
| Moonshot  | ✅        | ✅    | ❌     | ❌         | ✅        | ✅        |
| Zhipu     | ✅        | ✅    | ✅     | ✅         | ❌        | ✅        |
| Qwen      | ✅        | ✅    | ✅     | ✅         | ✅        | ✅        |
| Gemini    | ✅        | ✅    | ✅     | ✅         | ❌        | ✅        |
| MiniMax   | ✅        | ✅    | ❌     | ❌         | ✅        | ✅        |

## Choosing an Adapter

### By Feature

**Vision & Multimodal**

- OpenAI (GPT-4o), Anthropic (Claude 3), Qwen (Qwen-VL), Gemini (Gemini Pro Vision), Zhipu (GLM-4V)

**Long Context**

- Gemini (1M+ tokens), Anthropic (200K), Moonshot (200K)

**Coding**

- MiniMax (MiniMax-M2.1), DeepSeek (DeepSeek Coder), OpenAI (GPT-4), Anthropic (Claude 3.5 Sonnet)

**Reasoning**

- MiniMax (Interleaved Thinking), OpenAI (o3, o4-mini), DeepSeek (DeepSeek Reasoner), Moonshot (Kimi K2 Thinking)

### By Price

**Most Economical:** DeepSeek, Qwen

**Mid-range:** OpenAI GPT-3.5, Moonshot

**Premium:** OpenAI GPT-4, Anthropic Claude, Gemini Pro

### By OpenAI Compatibility

These adapters are OpenAI-compatible and can be seamlessly swapped:

- DeepSeek (fully compatible)
- MiniMax (fully compatible)
- Moonshot (fully compatible)
- Zhipu (fully compatible)
- Qwen (mostly compatible, minor differences)
- Gemini (requires format conversion)

## Quick Start

```bash tab="pnpm"
pnpm add @amux.ai/llm-bridge @amux.ai/adapter-openai @amux.ai/adapter-anthropic
```

```bash tab="npm"
npm install @amux.ai/llm-bridge @amux.ai/adapter-openai @amux.ai/adapter-anthropic
```

```bash tab="yarn"
yarn add @amux.ai/llm-bridge @amux.ai/adapter-openai @amux.ai/adapter-anthropic
```

### Basic Usage

```typescript
import { createBridge } from '@amux.ai/llm-bridge'
import { openaiAdapter } from '@amux.ai/adapter-openai'
import { anthropicAdapter } from '@amux.ai/adapter-anthropic'

// Accept OpenAI format, call Claude API
const bridge = createBridge({
  inbound: openaiAdapter,
  outbound: anthropicAdapter,
  config: {
    apiKey: process.env.ANTHROPIC_API_KEY,
  },
})

const response = await bridge.chat({
  model: 'gpt-4',
  messages: [{ role: 'user', content: 'Hello!' }],
})
```

## Creating Custom Adapters

Need to support other LLM providers? Create a custom adapter:

```typescript
import type { LLMAdapter } from '@amux.ai/llm-bridge'

export const myAdapter: LLMAdapter = {
  name: 'my-provider',
  version: '1.0.0',
  capabilities: {
    streaming: true,
    tools: true,
    vision: false,
    multimodal: false,
    systemPrompt: true,
    toolChoice: true,
  },
  inbound: {
    parseRequest: (request) => {
      /* ... */
    },
    parseResponse: (response) => {
      /* ... */
    },
    parseStream: (stream) => {
      /* ... */
    },
    parseError: (error) => {
      /* ... */
    },
  },
  outbound: {
    buildRequest: (ir) => {
      /* ... */
    },
    buildResponse: (ir) => {
      /* ... */
    },
  },
  getInfo() {
    return {
      name: this.name,
      version: this.version,
      capabilities: this.capabilities,
      endpoint: {
        baseUrl: 'https://api.my-provider.com',
        chatPath: '/v1/chat',
      },
    }
  },
}
```

See the [Custom Adapter Guide](/en/docs/adapters/custom-adapter) for a complete tutorial.

## Next Steps

<Cards>
  <Card title="OpenAI Adapter" href="/en/docs/adapters/openai">
    Learn how to use the OpenAI adapter
  </Card>
  <Card title="Custom Adapter Guide" href="/en/docs/adapters/custom-adapter">
    Create your own adapter
  </Card>
  <Card title="Adapter API" href="/en/docs/api/adapters">
    View the complete Adapter API reference
  </Card>
</Cards>

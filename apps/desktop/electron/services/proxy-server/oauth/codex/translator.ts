import { randomUUID } from 'node:crypto'

import type { FastifyRequest, FastifyReply } from 'fastify'

import type { OAuthTranslator } from '../types'
import { getOAuthLogger } from '../logger'
import { getOAuthPoolManager } from '../pool-manager'

import { CodexRequestTransformer } from './request-transformer'
import { CodexResponseTransformer } from './response-transformer'

/**
 * Codex API é”™è¯¯ï¼ˆä¿ç•™åŸå§‹çŠ¶æ€ç å’Œé”™è¯¯è¯¦æƒ…ï¼‰
 */
class CodexAPIError extends Error {
  constructor(
    message: string,
    public statusCode: number,
    public errorBody: any
  ) {
    super(message)
    this.name = 'CodexAPIError'
  }
}

/**
 * Codex OAuth è½¬æ¢æœåŠ¡
 * æ ‡å‡† OpenAI æ ¼å¼ â†” Codex ç‰¹æ®Šæ ¼å¼
 */
export class CodexTranslator implements OAuthTranslator {
  standardAdapterType = 'openai'
  
  private requestTransformer = new CodexRequestTransformer()
  private responseTransformer = new CodexResponseTransformer()
  private poolManager = getOAuthPoolManager()
  private logger = getOAuthLogger()
  
  private readonly CODEX_API_URL = 'https://chatgpt.com/backend-api/codex/responses'
  
  async handle(
    request: FastifyRequest,
    reply: FastifyReply
  ): Promise<void> {
    const openaiRequest = request.body as any
    
    // 1. éªŒè¯è¯·æ±‚
    if (!openaiRequest || !openaiRequest.messages) {
      reply.status(400).send({
        error: {
          message: 'Invalid request: messages are required',
          type: 'invalid_request_error'
        }
      })
      return
    }
    
    // 2. è½¬æ¢ä¸º Codex æ ¼å¼
    const codexRequest = this.requestTransformer.transform(openaiRequest)
    const isStream = codexRequest.stream !== false
    
    // 3. ä½¿ç”¨ Pool Manager çš„é€šç”¨é‡è¯•æœºåˆ¶æ‰§è¡Œè¯·æ±‚
    try {
      await this.poolManager.executeWithRetry('codex', async (selection) => {
        const startTime = Date.now()
        const accountId = selection.account.id
        const model = openaiRequest.model
        
        // âš ï¸ æ£€æŸ¥ reply çŠ¶æ€ï¼šå¦‚æœå·²ç»å¼€å§‹å“åº”ï¼Œæ— æ³•é‡è¯•
        const wasHeadersSent = reply.raw.headersSent
        if (wasHeadersSent) {
          console.error(`[CodexTranslator] âŒ Cannot retry: HTTP response already started`)
          throw new Error('Cannot retry: HTTP response already started')
        }
        
        try {
          // æ‰§è¡Œè¯·æ±‚ï¼ˆæµå¼æˆ–éæµå¼ï¼‰
          if (isStream) {
            await this.handleStreamRequest(
              codexRequest,
              selection.accessToken,
              selection.metadata,
              reply,
              accountId,
              model,
              startTime
            )
          } else {
            await this.handleNonStreamRequest(
              codexRequest,
              selection.accessToken,
              selection.metadata,
              reply,
              accountId,
              model,
              startTime
            )
          }
          
          // è¿”å› void è¡¨ç¤ºæˆåŠŸï¼ˆPool Manager ä¼šè®°å½•æˆåŠŸè´¦å·ï¼‰
        } catch (error) {
          const latency = Date.now() - startTime
          
          // è®°å½•å¤±è´¥ç»Ÿè®¡
          await this.logRequest({
            accountId,
            success: false,
            errorMessage: (error as Error).message,
            latencyMs: latency,
            model
          })
          
          // âš ï¸ æ£€æŸ¥æ˜¯å¦çœŸæ­£å¼€å§‹äº†æµå¼ä¼ è¾“ï¼ˆä¸åªæ˜¯å…³é—­è¿æ¥ï¼‰
          const isHeadersSentAfterError = reply.raw.headersSent
          const wasStreamStarted = wasHeadersSent !== isHeadersSentAfterError
          
          // å¦‚æœæµå¼ä¼ è¾“çœŸæ­£å¼€å§‹äº†ï¼ˆheaders ä» false å˜æˆ trueï¼‰ï¼Œä¸è¦é‡è¯•
          if (wasStreamStarted && isHeadersSentAfterError) {
            // ä¸é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œè®©å“åº”æ­£å¸¸å®Œæˆ
            return
          }
          
          // é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œè®© Pool Manager å¤„ç†é‡è¯•
          throw error
        }
      })
    } catch (error) {
      // âš ï¸ åªåœ¨ headers æœªå‘é€æ—¶æ‰èƒ½è®¾ç½®çŠ¶æ€ç 
      if (!reply.raw.headersSent) {
        // ğŸ”„ é€ä¼ åŸå§‹é”™è¯¯ç å’Œé”™è¯¯è¯¦æƒ…
        if (error instanceof CodexAPIError) {
          reply.status(error.statusCode).send({
            error: error.errorBody?.error || {
              message: error.message,
              type: 'codex_api_error'
            }
          })
        } else {
          // é API é”™è¯¯ï¼ˆå¦‚ç½‘ç»œé”™è¯¯ã€æ‰€æœ‰è´¦å·éƒ½å¤±è´¥ç­‰ï¼‰
          reply.status(502).send({
            error: {
              message: (error as Error).message || 'All retry attempts failed',
              type: 'oauth_pool_exhausted'
            }
          })
        }
      }
    }
  }
  
  /**
   * å¤„ç†æµå¼è¯·æ±‚
   * 
   * æ³¨æ„ï¼šæµå¼å“åº”ä¸€æ—¦å¼€å§‹ä¼ è¾“ï¼ˆè®¾ç½® SSE headersï¼‰ï¼Œå°±æ— æ³•é‡è¯•ã€‚
   * é‡è¯•åªé€‚ç”¨äºè¯·æ±‚å‰çš„é”™è¯¯ï¼ˆ429ã€401ã€ç½‘ç»œé”™è¯¯ç­‰ï¼‰ã€‚
   * ç©ºå“åº”è™½ç„¶ä¸ç†æƒ³ï¼Œä½†ä¼šæ­£å¸¸å®Œæˆä¼ è¾“å¹¶è®°å½•ä¸ºå¤±è´¥ã€‚
   */
  private async handleStreamRequest(
    codexRequest: any,
    accessToken: string,
    metadata: Record<string, unknown>,
    reply: FastifyReply,
    accountId: string,
    model: string,
    startTime: number
  ): Promise<void> {
    // âœ… æ ‡å¿—ï¼šæ˜¯å¦çœŸæ­£å¼€å§‹äº†æµå¼ä¼ è¾“
    let streamStarted = false
    
    try {
      // æ„å»º Codex è¯·æ±‚ headers
      const headers = this.buildCodexHeaders(accessToken, metadata)
      
      // è°ƒç”¨ Codex API
      const response = await fetch(this.CODEX_API_URL, {
        method: 'POST',
        headers,
        body: JSON.stringify(codexRequest)
      })
      
      if (!response.ok) {
        const errorText = await response.text().catch(() => 'Unable to read error body')
        let errorBody: any
        try {
          errorBody = JSON.parse(errorText)
        } catch {
          errorBody = { error: { message: errorText, type: 'unknown' } }
        }
        
        // ğŸ”„ æŠ›å‡ºåŒ…å«åŸå§‹çŠ¶æ€ç çš„é”™è¯¯
        throw new CodexAPIError(
          `Codex API error: ${response.status} ${response.statusText}`,
          response.status,
          errorBody
        )
      }
      
      // âœ… åªæœ‰åœ¨è¯·æ±‚æˆåŠŸåæ‰è®¾ç½® SSE headers
      reply.raw.setHeader('Content-Type', 'text/event-stream')
      reply.raw.setHeader('Cache-Control', 'no-cache')
      reply.raw.setHeader('Connection', 'keep-alive')
      
      // âœ… æ ‡è®°ï¼šæµå¼ä¼ è¾“å·²å¼€å§‹
      streamStarted = true
      
      if (!response.body) {
        throw new Error('Codex API returned no body')
      }
      
      // å¤„ç† SSE æµ
      const reader = response.body.getReader()
      const decoder = new TextDecoder()
      let buffer = ''
      let totalInputTokens = 0
      let totalOutputTokens = 0
      
      // eslint-disable-next-line no-constant-condition
      while (true) {
        const { done, value } = await reader.read()
        
        if (done) {
          break
        }
        
        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6).trim()
            
            if (data === '[DONE]') {
              continue
            }
            
            try {
              const codexEvent = JSON.parse(data)
              const openaiChunk = this.responseTransformer.transformStreamChunk(codexEvent)
              
              if (openaiChunk) {
                // æ”¶é›† usage ä¿¡æ¯
                if (openaiChunk.usage) {
                  totalInputTokens = openaiChunk.usage.prompt_tokens || 0
                  totalOutputTokens = openaiChunk.usage.completion_tokens || 0
                }
                
                // å‘é€ OpenAI æ ¼å¼çš„ chunk
                reply.raw.write(`data: ${JSON.stringify(openaiChunk)}\n\n`)
              }
            } catch (parseError) {
              // Skip invalid JSON
            }
          }
        }
      }
      
      // å‘é€ç»“æŸæ ‡è®°
      reply.raw.write('data: [DONE]\n\n')
      reply.raw.end()
      
      // è®°å½•æ—¥å¿—
      const latency = Date.now() - startTime
      const success = totalOutputTokens > 0
      
      await this.logRequest({
        accountId,
        success,
        inputTokens: totalInputTokens,
        outputTokens: totalOutputTokens,
        latencyMs: latency,
        model,
        errorMessage: success ? undefined : 'Empty response from API'
      })
      
    } catch (error) {
      // âœ… åªæœ‰åœ¨çœŸæ­£å¼€å§‹æµå¼ä¼ è¾“åæ‰å…³é—­è¿æ¥
      if (streamStarted && !reply.raw.writableEnded) {
        reply.raw.end()
      }
      
      throw error
    }
  }
  
  /**
   * å¤„ç†éæµå¼è¯·æ±‚
   */
  private async handleNonStreamRequest(
    codexRequest: any,
    accessToken: string,
    metadata: Record<string, unknown>,
    reply: FastifyReply,
    accountId: string,
    model: string,
    startTime: number
  ): Promise<void> {
    // æ„å»º Codex è¯·æ±‚ headers
    const headers = this.buildCodexHeaders(accessToken, metadata)
    
    // è°ƒç”¨ Codex API
    const response = await fetch(this.CODEX_API_URL, {
      method: 'POST',
      headers,
      body: JSON.stringify(codexRequest)
    })
    
    if (!response.ok) {
      const errorText = await response.text()
      let errorBody: any
      try {
        errorBody = JSON.parse(errorText)
      } catch {
        errorBody = { error: { message: errorText, type: 'unknown' } }
      }
      
      // ğŸ”„ æŠ›å‡ºåŒ…å«åŸå§‹çŠ¶æ€ç çš„é”™è¯¯
      throw new CodexAPIError(
        `Codex API error: ${response.status} ${response.statusText}`,
        response.status,
        errorBody
      )
    }
    
    const codexResponse = await response.json()
    
    // è½¬æ¢ä¸º OpenAI æ ¼å¼
    const openaiResponse = this.responseTransformer.transformNonStream(codexResponse)
    
    // âœ… æ£€æµ‹ç©ºå“åº”
    const outputTokens = openaiResponse.usage?.completion_tokens || 0
    
    if (outputTokens === 0) {
      throw new Error('Empty response from API')
    }
    
    // è®°å½•æ—¥å¿—
    const latency = Date.now() - startTime
    await this.logRequest({
      accountId,
      success: true,
      inputTokens: openaiResponse.usage?.prompt_tokens,
      outputTokens,
      latencyMs: latency,
      model
    })
    
    reply.send(openaiResponse)
  }
  
  /**
   * æ„å»º Codex è¯·æ±‚ Headers
   */
  private buildCodexHeaders(
    accessToken: string,
    metadata: Record<string, unknown>
  ): Record<string, string> {
    // ç”Ÿæˆ session ID
    const sessionId = randomUUID()
    
    const headers: Record<string, string> = {
      'Authorization': `Bearer ${accessToken}`,
      'Content-Type': 'application/json',
      'Version': '0.21.0',
      'Openai-Beta': 'responses=experimental',
      'User-Agent': 'codex_cli_rs/0.50.0 (Mac OS 26.0.1; arm64) Apple_Terminal/464',
      'Accept': 'text/event-stream',
      'Connection': 'Keep-Alive',
      'Originator': 'codex_cli_rs',
      'Session_id': sessionId,
      'Conversation_id': sessionId // Must be the same as Session_id
    }
    
    // æ·»åŠ å¯é€‰çš„ account_id header
    if (metadata.account_id) {
      headers['Chatgpt-Account-Id'] = String(metadata.account_id)
    }
    
    return headers
  }
  
  /**
   * è®°å½•è¯·æ±‚æ—¥å¿—
   */
  private async logRequest(params: {
    accountId: string
    success: boolean
    inputTokens?: number
    outputTokens?: number
    latencyMs?: number
    model?: string
    errorMessage?: string
  }): Promise<void> {
    // èšåˆç»Ÿè®¡
    await this.logger.logRequest({
      accountId: params.accountId,
      providerType: 'codex',
      success: params.success,
      inputTokens: params.inputTokens,
      outputTokens: params.outputTokens
    })
    
    // è¯¦ç»†æ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
    if (params.latencyMs || params.errorMessage) {
      await this.logger.logDetailedRequest({
        accountId: params.accountId,
        providerType: 'codex',
        model: params.model,
        success: params.success,
        inputTokens: params.inputTokens,
        outputTokens: params.outputTokens,
        latencyMs: params.latencyMs,
        errorMessage: params.errorMessage
      })
    }
  }
}
